{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imp import reload\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys,math\n",
    "import sistercellclass as scc; reload(scc)\n",
    "import os\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "# %matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [16, 9]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir   = '/home/lukas/projects/sistercells/experiments/SISTERS-NONSISTERS/SISTERS/'\n",
    "datafiles = [os.path.join(datadir,fn) for fn in os.listdir(datadir) if os.path.splitext(fn)[1][1:].upper() == 'XLS']\n",
    "\n",
    "#datafiles = ['/home/lukas/projects/sistercells/experiments/SISTERS-NONSISTERS/SISTERS/072818POS9_ch2t_sis2.xls']\n",
    "\n",
    "data      = scc.SisterCellData(infiles = datafiles, debugmode = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for dataID,filename,x in data:\n",
    "    #print dataID,filename\n",
    "    cdivA,cdivB = data.CellDivisionTrajectory(dataID)\n",
    "    #print np.array(cdivA['generationtimeA']),np.array(cdivB['generationtimeB'])\n",
    "    if dataID == 0:\n",
    "        gentime = np.concatenate([np.array(cdivA['generationtimeA']),np.array(cdivB['generationtimeB'])])\n",
    "    else:\n",
    "        gentime = np.concatenate([gentime,np.array(cdivA['generationtimeA']),np.array(cdivB['generationtimeB'])])\n",
    "    #print\n",
    "\n",
    "#np.savetxt('tmp.txt',gentime)\n",
    "#plt.hist(gentime,range=(0,2),bins=40,log=True)\n",
    "#print gentime\n",
    "#print max(gentime)\n",
    "#gth = dict()\n",
    "#for x in np.arange(0,2.1,.05):\n",
    "#    gth['{:.2f}'.format(x)] = 0\n",
    "#for g in gentime:\n",
    "#    gth['{:.2f}'.format(g)] += 1\n",
    "\n",
    "#print gth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autocorrelation (x) :\n",
    "    \"\"\"\n",
    "    Compute the autocorrelation of the signal, based on the properties of the\n",
    "    power spectral density of the signal.\n",
    "    \"\"\"\n",
    "    xp = x-np.mean(x)\n",
    "    f = np.fft.fft(xp)\n",
    "    p = np.array([np.real(v)**2+np.imag(v)**2 for v in f])\n",
    "    pi = np.fft.ifft(p)\n",
    "    return np.real(pi)[:x.size/2]/np.sum(xp**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acf = dict()\n",
    "for dataID,filename,x in data:\n",
    "    a,b = data.CellDivisionTrajectory(dataID)\n",
    "    for k in [kk for kk in a.keys() if kk[:4]!='time']:\n",
    "        if not k[:-1] in acf.keys():\n",
    "            acf[k[:-1]] = list()\n",
    "        if len(a[k]) > 0:\n",
    "            tmpacf = autocorrelation(a[k])\n",
    "            if not np.isnan(tmpacf).any():\n",
    "                acf[k[:-1]].append(tmpacf)\n",
    "        if len(b[k[:-1]+'B']) > 0:\n",
    "            tmpacf = autocorrelation(b[k[:-1] + 'B'])\n",
    "            if not np.isnan(tmpacf).any():\n",
    "                acf[k[:-1]].append(tmpacf)\n",
    "\n",
    "acf_avg = dict()\n",
    "for k in acf.keys():\n",
    "    maxl  = np.max([len(a) for a in acf[k]])\n",
    "    count = np.zeros(maxl)\n",
    "    acf_avg[k] = np.zeros(maxl)\n",
    "    for a in acf[k]:\n",
    "        acf_avg[k][:len(a)] += a\n",
    "        count[:len(a)] += 1.\n",
    "    acf_avg[k] /= count\n",
    "    print k\n",
    "    #print acf_avg[k]\n",
    "    plt.plot(np.arange(15),acf_avg[k][:15],label = k)\n",
    "plt.plot(np.arange(15),np.zeros(15))\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(count)\n",
    "\n",
    "for k in acf_avg.keys():\n",
    "    np.savetxt('ACF_{}.txt'.format(k),np.array([np.arange(len(acf_avg[k])),acf_avg[k]]).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gauss(x,mean,sigma2):\n",
    "    return np.exp(-(x-mean)**2/(2.*sigma2))/np.sqrt(2*math.pi*sigma2)\n",
    "\n",
    "maxcount = 30\n",
    "\n",
    "countdiv = np.zeros(maxcount)\n",
    "for dataID,fn,x in data:\n",
    "    a,b = data.CellDivisionTrajectory(dataID)\n",
    "    for t in np.array(a['generationtimeA']/.05,dtype=int):\n",
    "        if t < maxcount: countdiv[t] += 1\n",
    "    for t in np.array(b['generationtimeB']/.05,dtype=int):\n",
    "        if t < maxcount: countdiv[t] += 1\n",
    "\n",
    "plt.plot(np.arange(maxcount),np.log10(countdiv/np.sum(countdiv)))\n",
    "plt.plot(np.arange(start=0,stop=maxcount,step=.05),np.log10(gauss(np.arange(start=0,stop=maxcount,step=.05),10.968599386592668,7.605410963650854)))\n",
    "plt.ylim((-np.log10(np.sum(countdiv))-.5,1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = np.sum(np.arange(maxcount) * countdiv)/np.sum(countdiv)\n",
    "v = np.sum(np.arange(maxcount)**2 * countdiv)/np.sum(countdiv) - (np.sum(np.arange(maxcount)*countdiv)/np.sum(countdiv))**2\n",
    "print 'mean: {}, sigma2: {}'.format(m,v)\n",
    "\n",
    "print 'count all division events: {}'.format(np.sum(countdiv,dtype=int))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class ARMA in module statsmodels.tsa.arima_model:\n",
      "\n",
      "class ARMA(statsmodels.tsa.base.tsa_model.TimeSeriesModel)\n",
      " |  Autoregressive Moving Average ARMA(p,q) Model\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  endog : array-like\n",
      " |      The endogenous variable.\n",
      " |  order : iterable\n",
      " |      The (p,q) order of the model for the number of AR parameters,\n",
      " |      differences, and MA parameters to use.\n",
      " |  exog : array-like, optional\n",
      " |      An optional array of exogenous variables. This should *not* include a\n",
      " |      constant or trend. You can specify this in the `fit` method.\n",
      " |  dates : array-like of datetime, optional\n",
      " |      An array-like object of datetime objects. If a pandas object is given\n",
      " |      for endog or exog, it is assumed to have a DateIndex.\n",
      " |  freq : str, optional\n",
      " |      The frequency of the time-series. A Pandas offset or 'B', 'D', 'W',\n",
      " |      'M', 'A', or 'Q'. This is optional if dates are given.\n",
      " |  \n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  If exogenous variables are given, then the model that is fit is\n",
      " |  \n",
      " |  .. math::\n",
      " |  \n",
      " |     \\phi(L)(y_t - X_t\\beta) = \\theta(L)\\epsilon_t\n",
      " |  \n",
      " |  where :math:`\\phi` and :math:`\\theta` are polynomials in the lag\n",
      " |  operator, :math:`L`. This is the regression model with ARMA errors,\n",
      " |  or ARMAX model. This specification is used, whether or not the model\n",
      " |  is fit using conditional sum of square or maximum-likelihood, using\n",
      " |  the `method` argument in\n",
      " |  :meth:`statsmodels.tsa.arima_model.ARMA.fit`. Therefore, for\n",
      " |  now, `css` and `mle` refer to estimation methods only. This may\n",
      " |  change for the case of the `css` model in future versions.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      ARMA\n",
      " |      statsmodels.tsa.base.tsa_model.TimeSeriesModel\n",
      " |      statsmodels.base.model.LikelihoodModel\n",
      " |      statsmodels.base.model.Model\n",
      " |      __builtin__.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, endog, order, exog=None, dates=None, freq=None, missing='none')\n",
      " |  \n",
      " |  fit(self, start_params=None, trend='c', method='css-mle', transparams=True, solver='lbfgs', maxiter=50, full_output=1, disp=5, callback=None, start_ar_lags=None, **kwargs)\n",
      " |      Fits ARMA(p,q) model using exact maximum likelihood via Kalman filter.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      start_params : array-like, optional\n",
      " |          Starting parameters for ARMA(p,q). If None, the default is given\n",
      " |          by ARMA._fit_start_params.  See there for more information.\n",
      " |      transparams : bool, optional\n",
      " |          Whehter or not to transform the parameters to ensure stationarity.\n",
      " |          Uses the transformation suggested in Jones (1980).  If False,\n",
      " |          no checking for stationarity or invertibility is done.\n",
      " |      method : str {'css-mle','mle','css'}\n",
      " |          This is the loglikelihood to maximize.  If \"css-mle\", the\n",
      " |          conditional sum of squares likelihood is maximized and its values\n",
      " |          are used as starting values for the computation of the exact\n",
      " |          likelihood via the Kalman filter.  If \"mle\", the exact likelihood\n",
      " |          is maximized via the Kalman Filter.  If \"css\" the conditional sum\n",
      " |          of squares likelihood is maximized.  All three methods use\n",
      " |          `start_params` as starting parameters.  See above for more\n",
      " |          information.\n",
      " |      trend : str {'c','nc'}\n",
      " |          Whether to include a constant or not.  'c' includes constant,\n",
      " |          'nc' no constant.\n",
      " |      solver : str or None, optional\n",
      " |          Solver to be used.  The default is 'lbfgs' (limited memory\n",
      " |          Broyden-Fletcher-Goldfarb-Shanno).  Other choices are 'bfgs',\n",
      " |          'newton' (Newton-Raphson), 'nm' (Nelder-Mead), 'cg' -\n",
      " |          (conjugate gradient), 'ncg' (non-conjugate gradient), and\n",
      " |          'powell'. By default, the limited memory BFGS uses m=12 to\n",
      " |          approximate the Hessian, projected gradient tolerance of 1e-8 and\n",
      " |          factr = 1e2. You can change these by using kwargs.\n",
      " |      maxiter : int, optional\n",
      " |          The maximum number of function evaluations. Default is 50.\n",
      " |      tol : float\n",
      " |          The convergence tolerance.  Default is 1e-08.\n",
      " |      full_output : bool, optional\n",
      " |          If True, all output from solver will be available in\n",
      " |          the Results object's mle_retvals attribute.  Output is dependent\n",
      " |          on the solver.  See Notes for more information.\n",
      " |      disp : int, optional\n",
      " |          If True, convergence information is printed.  For the default\n",
      " |          l_bfgs_b solver, disp controls the frequency of the output during\n",
      " |          the iterations. disp < 0 means no output in this case.\n",
      " |      callback : function, optional\n",
      " |          Called after each iteration as callback(xk) where xk is the current\n",
      " |          parameter vector.\n",
      " |      start_ar_lags : int, optional\n",
      " |          Parameter for fitting start_params. When fitting start_params,\n",
      " |          residuals are obtained from an AR fit, then an ARMA(p,q) model is\n",
      " |          fit via OLS using these residuals. If start_ar_lags is None, fit\n",
      " |          an AR process according to best BIC. If start_ar_lags is not None,\n",
      " |          fits an AR process with a lag length equal to start_ar_lags.\n",
      " |          See ARMA._fit_start_params_hr for more information.\n",
      " |      kwargs\n",
      " |          See Notes for keyword arguments that can be passed to fit.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      statsmodels.tsa.arima_model.ARMAResults class\n",
      " |      \n",
      " |      See also\n",
      " |      --------\n",
      " |      statsmodels.base.model.LikelihoodModel.fit : for more information\n",
      " |          on using the solvers.\n",
      " |      ARMAResults : results class returned by fit\n",
      " |      \n",
      " |      Notes\n",
      " |      ------\n",
      " |      If fit by 'mle', it is assumed for the Kalman Filter that the initial\n",
      " |      unkown state is zero, and that the inital variance is\n",
      " |      P = dot(inv(identity(m**2)-kron(T,T)),dot(R,R.T).ravel('F')).reshape(r,\n",
      " |      r, order = 'F')\n",
      " |  \n",
      " |  geterrors(self, params)\n",
      " |      Get the errors of the ARMA process.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      params : array-like\n",
      " |          The fitted ARMA parameters\n",
      " |      order : array-like\n",
      " |          3 item iterable, with the number of AR, MA, and exogenous\n",
      " |          parameters, including the trend\n",
      " |  \n",
      " |  hessian(self, params)\n",
      " |      Compute the Hessian at params,\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This is a numerical approximation.\n",
      " |  \n",
      " |  loglike(self, params, set_sigma2=True)\n",
      " |      Compute the log-likelihood for ARMA(p,q) model\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Likelihood used depends on the method set in fit\n",
      " |  \n",
      " |  loglike_css(self, params, set_sigma2=True)\n",
      " |      Conditional Sum of Squares likelihood function.\n",
      " |  \n",
      " |  loglike_kalman(self, params, set_sigma2=True)\n",
      " |      Compute exact loglikelihood for ARMA(p,q) model by the Kalman Filter.\n",
      " |  \n",
      " |  predict(self, params, start=None, end=None, exog=None, dynamic=False)\n",
      " |      ARMA model in-sample and out-of-sample prediction\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      \n",
      " |          params : array-like\n",
      " |          The fitted parameters of the model.\n",
      " |      start : int, str, or datetime\n",
      " |          Zero-indexed observation number at which to start forecasting, ie.,\n",
      " |          the first forecast is start. Can also be a date string to\n",
      " |          parse or a datetime type.\n",
      " |      end : int, str, or datetime\n",
      " |          Zero-indexed observation number at which to end forecasting, ie.,\n",
      " |          the first forecast is start. Can also be a date string to\n",
      " |          parse or a datetime type. However, if the dates index does not\n",
      " |          have a fixed frequency, end must be an integer index if you\n",
      " |          want out of sample prediction.\n",
      " |      exog : array-like, optional\n",
      " |          If the model is an ARMAX and out-of-sample forecasting is\n",
      " |          requested, exog must be given. Note that you'll need to pass\n",
      " |          `k_ar` additional lags for any exogenous variables. E.g., if you\n",
      " |          fit an ARMAX(2, q) model and want to predict 5 steps, you need 7\n",
      " |          observations to do this.\n",
      " |      dynamic : bool, optional\n",
      " |          The `dynamic` keyword affects in-sample prediction. If dynamic\n",
      " |          is False, then the in-sample lagged values are used for\n",
      " |          prediction. If `dynamic` is True, then in-sample forecasts are\n",
      " |          used in place of lagged dependent variables. The first forecasted\n",
      " |          value is `start`.\n",
      " |      \n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      predict : array\n",
      " |          The predicted values.\n",
      " |      \n",
      " |      \n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Use the results predict method instead.\n",
      " |  \n",
      " |  score(self, params)\n",
      " |      Compute the score function at params.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This is a numerical approximation.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from statsmodels.tsa.base.tsa_model.TimeSeriesModel:\n",
      " |  \n",
      " |  exog_names\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from statsmodels.base.model.LikelihoodModel:\n",
      " |  \n",
      " |  information(self, params)\n",
      " |      Fisher information matrix of model\n",
      " |      \n",
      " |      Returns -Hessian of loglike evaluated at params.\n",
      " |  \n",
      " |  initialize(self)\n",
      " |      Initialize (possibly re-initialize) a Model instance. For\n",
      " |      instance, the design matrix of a linear model may change\n",
      " |      and some things must be recomputed.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from statsmodels.base.model.Model:\n",
      " |  \n",
      " |  from_formula(cls, formula, data, subset=None, drop_cols=None, *args, **kwargs) from __builtin__.type\n",
      " |      Create a Model from a formula and dataframe.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      formula : str or generic Formula object\n",
      " |          The formula specifying the model\n",
      " |      data : array-like\n",
      " |          The data for the model. See Notes.\n",
      " |      subset : array-like\n",
      " |          An array-like object of booleans, integers, or index values that\n",
      " |          indicate the subset of df to use in the model. Assumes df is a\n",
      " |          `pandas.DataFrame`\n",
      " |      drop_cols : array-like\n",
      " |          Columns to drop from the design matrix.  Cannot be used to\n",
      " |          drop terms involving categoricals.\n",
      " |      args : extra arguments\n",
      " |          These are passed to the model\n",
      " |      kwargs : extra keyword arguments\n",
      " |          These are passed to the model with one exception. The\n",
      " |          ``eval_env`` keyword is passed to patsy. It can be either a\n",
      " |          :class:`patsy:patsy.EvalEnvironment` object or an integer\n",
      " |          indicating the depth of the namespace to use. For example, the\n",
      " |          default ``eval_env=0`` uses the calling namespace. If you wish\n",
      " |          to use a \"clean\" environment set ``eval_env=-1``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      model : Model instance\n",
      " |      \n",
      " |      Notes\n",
      " |      ------\n",
      " |      data must define __getitem__ with the keys in the formula terms\n",
      " |      args and kwargs are passed on to the model instantiation. E.g.,\n",
      " |      a numpy structured or rec array, a dictionary, or a pandas DataFrame.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from statsmodels.base.model.Model:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  endog_names\n",
      " |      Names of endogenous variables\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(sm.tsa.ARMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
